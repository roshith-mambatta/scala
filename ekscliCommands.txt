
sudo apt install python3-pip
pip3 install --upgrade --user awscli
root@roshith:/opt/spark/bin# aws --version
aws-cli/1.18.93 Python/3.8.2 Linux/5.4.0-40-generic botocore/1.17.16

eksctl create cluster \
--name demoEksCluster \
--version 1.16 \
--region eu-west-1 \
--nodegroup-name demoEksCluster-workers \
--node-type t3.medium \
--nodes 2 \
--nodes-min 1 \
--nodes-max 4 \
--managed


root@roshith:/home/roshith# eksctl create cluster \
> --name demoEksCluster \
> --version 1.16 \
> --region eu-west-1 \
> --nodegroup-name demoEksCluster-workers \
> --node-type t3.medium \
> --nodes 2 \
> --nodes-min 1 \
> --nodes-max 4 \
> --managed
[ℹ]  eksctl version 0.23.0
[ℹ]  using region eu-west-1
[ℹ]  setting availability zones to [eu-west-1b eu-west-1a eu-west-1c]
[ℹ]  subnets for eu-west-1b - public:192.168.0.0/19 private:192.168.96.0/19
[ℹ]  subnets for eu-west-1a - public:192.168.32.0/19 private:192.168.128.0/19
[ℹ]  subnets for eu-west-1c - public:192.168.64.0/19 private:192.168.160.0/19
[ℹ]  using Kubernetes version 1.16
[ℹ]  creating EKS cluster "demoEksCluster" in "eu-west-1" region with managed nodes
[ℹ]  will create 2 separate CloudFormation stacks for cluster itself and the initial managed nodegroup
[ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=eu-west-1 --cluster=demoEksCluster'
[ℹ]  CloudWatch logging will not be enabled for cluster "demoEksCluster" in "eu-west-1"
[ℹ]  you can enable it with 'eksctl utils update-cluster-logging --region=eu-west-1 --cluster=demoEksCluster'
[ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "demoEksCluster" in "eu-west-1"
[ℹ]  2 sequential tasks: { create cluster control plane "demoEksCluster", 2 sequential sub-tasks: { no tasks, create managed nodegroup "demoEksCluster-workers" } }
[ℹ]  building cluster stack "eksctl-demoEksCluster-cluster"
[ℹ]  deploying stack "eksctl-demoEksCluster-cluster"
[ℹ]  building managed nodegroup stack "eksctl-demoEksCluster-nodegroup-demoEksCluster-workers"
[ℹ]  deploying stack "eksctl-demoEksCluster-nodegroup-demoEksCluster-workers"
[ℹ]  waiting for the control plane availability...
[✔]  saved kubeconfig as "/root/.kube/config"
[ℹ]  no tasks
[✔]  all EKS cluster resources for "demoEksCluster" have been created
[ℹ]  nodegroup "demoEksCluster-workers" has 2 node(s)
[ℹ]  node "ip-192-168-1-0.eu-west-1.compute.internal" is ready
[ℹ]  node "ip-192-168-59-239.eu-west-1.compute.internal" is ready
[ℹ]  waiting for at least 1 node(s) to become ready in "demoEksCluster-workers"
[ℹ]  nodegroup "demoEksCluster-workers" has 2 node(s)
[ℹ]  node "ip-192-168-1-0.eu-west-1.compute.internal" is ready
[ℹ]  node "ip-192-168-59-239.eu-west-1.compute.internal" is ready
[ℹ]  kubectl command should work with "/root/.kube/config", try 'kubectl get nodes'
[✔]  EKS cluster "demoEksCluster" in "eu-west-1" region is ready


python3 --version
sudo apt-get update
#sudo apt upgrade -y
sudo apt install python3-pip -y

Install awscli:
----------------------------------------
sudo apt-get install -y awscli
aws --version
# Get the "rootkey" from the aws console and then
aws configure
pip3 install --upgrade --user awscli

Install aws-iam-authenticator:
----------------------------------------
curl -o aws-iam-authenticator https://amazon-eks.s3.us-west-2.amazonaws.com/1.16.8/2020-04-16/bin/linux/amd64/aws-iam-authenticator
chmod +x ./aws-iam-authenticator
mkdir -p $HOME/bin && cp ./aws-iam-authenticator $HOME/bin/aws-iam-authenticator && export PATH=$PATH:$HOME/bin
echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
aws-iam-authenticator help


Install eksctl
----------------------------------------
curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin
eksctl version


Install kubectl:
----------------------------------------
curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.16.8/2020-04-16/bin/linux/amd64/kubectl
chmod +x ./kubectl
#sudo mv ./kubectl /usr/local/bin
mkdir -p $HOME/bin && mv ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
echo 'export PATH=$PATH:$HOME/bin' >> ~/.bash_profile
kubectl version --short --client


Install Docker:
----------------------------------------
sudo apt install -y docker.io
sudo docker version
sudo docker login -u "sidhartharay" -p "Abc-1234" docker.io


Create ECR repository
----------------------------------------
aws ecr get-login --region eu-west-1 --no-include-email
sudo docker login -u AWS -p abcdef https://789145380093.dkr.ecr.eu-west-1.amazonaws.com
# Should see "Login Succeeded" output
aws ecr create-repository --repository-name demo
{
    "repository": {
        "repositoryArn": "arn:aws:ecr:eu-west-1:789145380093:repository/demo",
        "registryId": "789145380093",
        "repositoryName": "demo",
        "repositoryUri": "789145380093.dkr.ecr.eu-west-1.amazonaws.com/demo",
        "createdAt": 1593678134.0,
        "imageTagMutability": "MUTABLE",
        "imageScanningConfiguration": {
            "scanOnPush": false
        }
    }
}

Install spark and download the other required libraries
----------------------------------------
sudo apt-get install openjdk-8-jdk -y
# sudo apt install -y default-jdk
# Scala Installation
wget www.scala-lang.org/files/archive/scala-2.11.8.deb
sudo dpkg -i scala-2.11.8.deb
# sbt Installation
echo "deb https://dl.bintray.com/sbt/debian /" | sudo tee -a /etc/apt/sources.list.d/sbt.list
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823
sudo apt-get update
sudo apt-get install sbt
# sudo apt install default-jdk scala git -y
java -version; javac -version; scala -version; git --version
wget https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz
tar xvf spark-2*
sudo mv spark-2.4.5-bin-hadoop2.7 /opt/spark
echo "export SPARK_HOME=/opt/spark" >> ~/.profile
echo "export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin" >> ~/.profile
echo "export PYSPARK_PYTHON=/usr/bin/python3" >> ~/.profile
source ~/.profile
rm spark-2.4.5-bin-hadoop2.7.tgz 


Build spark job image:
----------------------------------------
Step 1: Create directory spark-demo and download the necessary librararies
mkdir spark-demo
cd spark-demo
wget https://archive.apache.org/dist/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz
tar xvf hadoop-3.1.2.tar.gz 
rm hadoop-3.1.2.tar.gz 
wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.1.2/hadoop-aws-3.1.2.jar
wget https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.271/aws-java-sdk-bundle-1.11.271.jar

Step 2: Copy the Dockerfile
vi Dockerfile
FROM arverma/spark:v1
ADD hadoop-3.1.2 /hadoop-3.1.2
COPY hadoop-aws-3.1.2.jar $SPARK_HOME/jars
COPY aws-java-sdk-bundle-1.11.271.jar $SPARK_HOME/jars
COPY DfTest.py /tmp/DfTest.py
ENV HADOOP_HOME /hadoop-3.1.2

ENV SPARK_DIST_CLASSPATH="$HADOOP_HOME/etc/hadoop/:$HADOOP_HOME/share/hadoop/common/lib/:$HADOOP_HOME/share/hadoop/common/:$HADOOP_HOME/share/hadoop/hdfs/:$HADOOP_HOME/share/hadoop/hdfs/lib/:$HADOOP_HOME/share/hadoop/hdfs/:$HADOOP_HOME/share/hadoop/yarn/lib/:$HADOOP_HOME/share/hadoop/yarn/:$HADOOP_HOME/share/hadoop/mapreduce/lib/:$HADOOP_HOME/share/hadoop/mapreduce/:$HADOOP_HOME/share/hadoop/tools/lib/*"
ENV SPARK_EXTRA_CLASSPATH="$HADOOP_HOME/etc/hadoop/:$HADOOP_HOME/share/hadoop/common/lib/:$HADOOP_HOME/share/hadoop/common/:$HADOOP_HOME/share/hadoop/hdfs/:$HADOOP_HOME/share/hadoop/hdfs/lib/:$HADOOP_HOME/share/hadoop/hdfs/:$HADOOP_HOME/share/hadoop/yarn/lib/:$HADOOP_HOME/share/hadoop/yarn/:$HADOOP_HOME/share/hadoop/mapreduce/lib/:$HADOOP_HOME/share/hadoop/mapreduce/:$HADOOP_HOME/share/hadoop/tools/lib/*"

Step 3: Create demo spark code
vi DfTest.py
from pyspark.sql.types import *
from pyspark.sql import SparkSession
import os.path

if _name_ == '_main_':
	os.environ["PYSPARK_SUBMIT_ARGS"] = (
		'--packages "org.apache.hadoop:hadoop-aws:2.7.4" pyspark-shell'
	)
	# Create the SparkSession
	spark = SparkSession \
		.builder \
		.appName("Read Files") \
		.getOrCreate()
	test_schema = StructType([StructField("Words", StringType()), StructField("total", IntegerType())])
	test_list = [['Hello', 1], ['I am fine', 3]]
	df = spark.createDataFrame(test_list, schema=test_schema) 
	df.show()


Step 4: Build the spark job image
sudo docker build -t 789145380093.dkr.ecr.eu-west-1.amazonaws.com/demo:1.0 . 
sudo docker push 789145380093.dkr.ecr.eu-west-1.amazonaws.com/demo:1.0


Step 5: Create a kubernetes cluster
eksctl create cluster --name demo-cluster-ec2 --region eu-west-1 


Step 6: Setup kubectl
export KUBECONFIG=$KUBECONFIG:~/.kube/config-sid1
aws eks --region eu-west-1 update-kubeconfig --name demo-cluster-ec2 
kubectl create serviceaccount spark
kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=default
kubectl cluster-info


/opt/spark/bin/spark-submit --deploy-mode cluster --master k8s://https://96E21A18DB9A3D591C31848EFBEC681F.sk1.eu-west-1.eks.amazonaws.com:443 --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark2 --conf spark.executor.instances=2 --conf spark.driver.memory=1g --conf=spark.executor.memory=1g --conf=spark.executor.cores=1 --conf spark.app.name=my_pyspark_job --conf spark.kubernetes.namespace=default --conf spark.kubernetes.driver.container.image=789145380093.dkr.ecr.eu-west-1.amazonaws.com/demo:1.0 --conf spark.kubernetes.executor.container.image=789145380093.dkr.ecr.eu-west-1.amazonaws.com/demo:1.0 local:///tmp/DfTest.py

/opt/spark/bin/spark-submit --deploy-mode cluster --master k8s://https://90405361FF56515E3CC30C3875582942.gr7.eu-west-1.eks.amazonaws.com:443  --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark --conf spark.executor.instances=2 --conf=spark.executor.cores=1 --conf spark.app.name=my_pyspark_job --conf spark.kubernetes.namespace=default --conf spark.kubernetes.driver.container.image=789145380093.dkr.ecr.eu-west-1.amazonaws.com/demo:1.2 --conf spark.kubernetes.executor.container.image=789145380093.dkr.ecr.eu-west-1.amazonaws.com/demo:1.2 local:///tmp/DfTest.py


kubectl describe secret spark-token-bbjhb

aws ecr get-login --region eu-west-1 --no-include-email

eksctl create cluster --name demo-cluster-ec2 --region eu-west-1 

kubectl get nodes
kubectl get pods 
kubectl get pods -o wide

kubectl create deployment demo-app-ec2-2 --image=905025710798.dkr.ecr.eu-west-1.amazonaws.com/demo:1.2 
kubectl expose deployment demo-app-ec2-2 --type=LoadBalancer --port 5000 --target-port 5000

kubectl get pods --no-headers=true | awk '/mypysparkjob/{print $1}'| xargs  kubectl delete pod
kubectl get pods --no-headers=true | awk '/demo-app/{print $1}'| xargs  kubectl delete pod

kubectl scale deployment demo-app-ec2-2 --replicas=3

while true; do sleep 0.1; curl http://afb1ae9730d1b4a00b22832246153578-208952965.eu-west-1.elb.amazonaws.com:5000/; echo -e;done

eksctl get nodegroup --cluster=demo-cluster-ec2 
eksctl scale nodegroup  --cluster=demo-cluster-ec2 --nodes=1 --name=ng-6e4a34a2 










kubectl delete service demo-app-ec2
kubectl delete mypysparkjob-1593308078991-driver-svc
eksctl delete cluster --name demo-cluster-ec2
